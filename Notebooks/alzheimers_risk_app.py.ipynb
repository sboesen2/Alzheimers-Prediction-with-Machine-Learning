{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a736b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "# If you're using matplotlib for visualizations, uncomment the following line:\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "class XGBoostClassifierWithEarlyStopping(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, early_stopping_rounds=10, **kwargs):\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.params = kwargs\n",
    "        self.model = None\n",
    "        self.best_iteration = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model = xgb.XGBClassifier(**self.params)\n",
    "        \n",
    "        # Train the model with manual early stopping\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        best_score = float('inf')\n",
    "        best_iteration = 0\n",
    "        for i in range(self.model.n_estimators):\n",
    "            self.model.n_estimators = i + 1\n",
    "            y_pred = self.model.predict_proba(X_val)\n",
    "            score = log_loss(y_val, y_pred)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_iteration = i\n",
    "            elif i - best_iteration >= self.early_stopping_rounds:\n",
    "                break\n",
    "        \n",
    "        # Retrain the model with the best number of iterations\n",
    "        self.best_iteration = best_iteration + 1\n",
    "        self.model.n_estimators = self.best_iteration\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {**super().get_params(deep), **self.params, 'early_stopping_rounds': self.early_stopping_rounds}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            setattr(self, param, value)\n",
    "        if 'early_stopping_rounds' in params:\n",
    "            self.early_stopping_rounds = params['early_stopping_rounds']\n",
    "        else:\n",
    "            self.params.update(params)\n",
    "        return self\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Users\\14807\\OneDrive\\Spreadsheets\\Data Science Capstone\\AI_ML_Biotech\\Data Collection\\Final Data Merging after Collection\\merged_alzheimers_data.csv')\n",
    "\n",
    "# Create binary target variable\n",
    "df['is_alzheimers'] = df['MAPPED_TRAIT'].str.contains('Alzheimer', case=False, na=False).astype(int)\n",
    "\n",
    "# Select relevant features\n",
    "features = ['STRONGEST SNP-RISK ALLELE', 'P-VALUE', 'OR or BETA', 'RISK ALLELE FREQUENCY', 'PVALUE_MLOG']\n",
    "X = df[features].copy()\n",
    "y = df['is_alzheimers']\n",
    "\n",
    "# Handle 'NR' in 'RISK ALLELE FREQUENCY'\n",
    "X['RISK ALLELE FREQUENCY'] = X['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_features = ['P-VALUE', 'OR or BETA', 'PVALUE_MLOG']\n",
    "categorical_features = ['STRONGEST SNP-RISK ALLELE']\n",
    "special_numeric = ['RISK ALLELE FREQUENCY']\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features),\n",
    "        ('special_num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), special_numeric)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBoostClassifierWithEarlyStopping(\n",
    "        use_label_encoder=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = dict(zip(np.unique(y), len(y) / (len(np.unique(y)) * np.bincount(y))))\n",
    "\n",
    "# Define expanded hyperparameter space\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'classifier__min_child_weight': [1, 3, 5],\n",
    "    'classifier__reg_alpha': [0.1, 0.5, 1],\n",
    "    'classifier__reg_lambda': [0.1, 0.5, 1],\n",
    "    'classifier__gamma': [0, 0.1, 0.2],\n",
    "    'classifier__scale_pos_weight': [class_weights[1] / class_weights[0]],\n",
    "    'classifier__early_stopping_rounds': [5, 10, 20]\n",
    "}\n",
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'  # Specify a scoring metric\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "logging.info(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba)}\")\n",
    "\n",
    "# Function to predict risk for new data\n",
    "def predict_alzheimers_risk(new_data):\n",
    "    try:\n",
    "        # Make prediction\n",
    "        risk_probability = best_model.predict_proba(new_data)[0][1]  # Probability of class 1 (Alzheimer's)\n",
    "        return risk_probability * 100  # Convert to percentage\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'alzheimers_risk_model.joblib')\n",
    "\n",
    "# Example usage\n",
    "new_person = pd.DataFrame({\n",
    "    'STRONGEST SNP-RISK ALLELE': ['rs429358-C'],\n",
    "    'P-VALUE': [1e-200],\n",
    "    'OR or BETA': [3.685],\n",
    "    'RISK ALLELE FREQUENCY': [0.15],\n",
    "    'PVALUE_MLOG': [200]\n",
    "}, index=[0])\n",
    "\n",
    "risk = predict_alzheimers_risk(new_person)\n",
    "if risk is not None:\n",
    "    print(f\"\\nPredicted Alzheimer's risk: {risk:.2f}%\")\n",
    "else:\n",
    "    print(\"Unable to predict risk due to an error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058062fd",
   "metadata": {},
   "source": [
    "# ML Model Step By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3644be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a86d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Data and Preprocess\n",
    "df = pd.read_csv(r'C:\\Users\\14807\\OneDrive\\Spreadsheets\\Data Science Capstone\\AI_ML_Biotech\\Data Collection\\Final Data Merging after Collection\\merged_alzheimers_data.csv')\n",
    "\n",
    "df['is_alzheimers'] = df['MAPPED_TRAIT'].str.contains('Alzheimer', case=False, na=False).astype(int)\n",
    "\n",
    "features = ['STRONGEST SNP-RISK ALLELE', 'P-VALUE', 'OR or BETA', 'RISK ALLELE FREQUENCY', 'PVALUE_MLOG']\n",
    "X = df[features].copy()\n",
    "y = df['is_alzheimers']\n",
    "\n",
    "X['RISK ALLELE FREQUENCY'] = X['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "\n",
    "numeric_features = ['P-VALUE', 'OR or BETA', 'PVALUE_MLOG']\n",
    "categorical_features = ['STRONGEST SNP-RISK ALLELE']\n",
    "special_numeric = ['RISK ALLELE FREQUENCY']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features),\n",
    "        ('special_num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), special_numeric)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff8b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Model Pipeline and Hyperparameters\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b22b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 01:00:44,403 - INFO - Best hyperparameters: {'classifier__n_estimators': 100, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 2, 'classifier__max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Hyperparameter Tuning and Model Fitting (Simplified)\n",
    "# Use a smaller subset of data for quicker hyperparameter tuning\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=0.1, random_state=42)\n",
    "\n",
    "# Simplify the hyperparameter space\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [50, 100],  # Reduced number of trees\n",
    "    'classifier__max_depth': [5, 10],       # Smaller tree depths\n",
    "    'classifier__min_samples_split': [2, 4],  # Simplified splits\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Reduce cross-validation folds to 2 for faster tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=5,  # Reduced iterations\n",
    "    cv=2,  # Reduced number of folds\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "# Fit the model on the sampled data\n",
    "random_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = random_search.best_estimator_\n",
    "logging.info(f\"Best hyperparameters: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9586e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93     13429\n",
      "           1       0.21      0.93      0.34       517\n",
      "\n",
      "    accuracy                           0.87     13946\n",
      "   macro avg       0.60      0.90      0.64     13946\n",
      "weighted avg       0.97      0.87      0.91     13946\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11639  1790]\n",
      " [   38   479]]\n",
      "\n",
      "ROC-AUC Score: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alzheimers_risk_model.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Model Evaluation and Persistence\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, 'alzheimers_risk_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7bbbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Important Features:\n",
      "                                               feature  importance\n",
      "0              STRONGEST SNP-RISK ALLELE_9:107541903-T    0.211260\n",
      "1          STRONGEST SNP-RISK ALLELE_chr10:125081474-C    0.173791\n",
      "2          STRONGEST SNP-RISK ALLELE_chr10:135344579-G    0.138925\n",
      "654                              RISK ALLELE FREQUENCY    0.119635\n",
      "57          STRONGEST SNP-RISK ALLELE_chr2:242393574-A    0.083728\n",
      "371  STRONGEST SNP-RISK ALLELE_rs2617921-? x rs1023...    0.069670\n",
      "40          STRONGEST SNP-RISK ALLELE_chr1:219365421-T    0.010111\n",
      "457               STRONGEST SNP-RISK ALLELE_rs527162-?    0.009330\n",
      "103           STRONGEST SNP-RISK ALLELE_chr8:3743232-C    0.008771\n",
      "98           STRONGEST SNP-RISK ALLELE_chr7:43397700-T    0.008745\n",
      "\n",
      "Optimal Threshold: 0.7350\n",
      "\n",
      "Classification Report with Optimal Threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     13429\n",
      "           1       1.00      0.49      0.66       517\n",
      "\n",
      "    accuracy                           0.98     13946\n",
      "   macro avg       0.99      0.75      0.83     13946\n",
      "weighted avg       0.98      0.98      0.98     13946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "feature_importance = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Get feature names for one-hot encoded categorical features\n",
    "onehot_encoder = best_model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "cat_feature_names = onehot_encoder.get_feature_names_out(categorical_features).tolist()\n",
    "\n",
    "# Combine all feature names\n",
    "feature_names = cat_feature_names + numeric_features + special_numeric\n",
    "\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False).head(10)\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Threshold Tuning\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores[:-1])]  # Exclude the last element as it's always 1\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Evaluate with optimal threshold\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "print(\"\\nClassification Report with Optimal Threshold:\")\n",
    "print(classification_report(y_test, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa76c969",
   "metadata": {},
   "source": [
    "### Model using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f2835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       180\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.45      0.50      0.47       200\n",
      "weighted avg       0.81      0.90      0.85       200\n",
      "\n",
      "\n",
      "ROC-AUC Score: 0.5264\n",
      "\n",
      "Optimal Threshold: 0.3903\n",
      "\n",
      "Classification Report with Optimal Threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       180\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.45      0.49      0.47       200\n",
      "weighted avg       0.81      0.89      0.85       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14807\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\14807\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\14807\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\14807\\AppData\\Local\\Temp\\ipykernel_11192\\3162761951.py:81: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Important Features:\n",
      "                         feature  importance\n",
      "1  STRONGEST SNP-RISK ALLELE_C-G    0.260623\n",
      "7          RISK ALLELE FREQUENCY    0.239900\n",
      "0  STRONGEST SNP-RISK ALLELE_A-T    0.229082\n",
      "2  STRONGEST SNP-RISK ALLELE_G-C    0.205597\n",
      "3  STRONGEST SNP-RISK ALLELE_T-A    0.019297\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ImprovedAlzheimersRiskModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.features = ['STRONGEST SNP-RISK ALLELE', 'P-VALUE', 'OR or BETA', 'RISK ALLELE FREQUENCY', 'PVALUE_MLOG']\n",
    "        self.numeric_features = ['P-VALUE', 'OR or BETA', 'PVALUE_MLOG']\n",
    "        self.categorical_features = ['STRONGEST SNP-RISK ALLELE']\n",
    "        self.special_numeric = ['RISK ALLELE FREQUENCY']\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        return ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]), self.numeric_features),\n",
    "                ('cat', Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "                ]), self.categorical_features),\n",
    "                ('special_num', Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]), self.special_numeric)\n",
    "            ])\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X = X[self.features]\n",
    "        X['RISK ALLELE FREQUENCY'] = X['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "\n",
    "        preprocessor = self.preprocess_data()\n",
    "\n",
    "        # Calculate class weights\n",
    "        class_weights = {0: 1, 1: len(y) / sum(y) / 2}  # Adjust weight for minority class\n",
    "\n",
    "        self.model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=2,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=42,\n",
    "                class_weight=class_weights\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X[self.features]\n",
    "        X['RISK ALLELE FREQUENCY'] = X['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = X[self.features]\n",
    "        X['RISK ALLELE FREQUENCY'] = X['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y, y_pred))\n",
    "        print(f\"\\nROC-AUC Score: {roc_auc_score(y, y_pred_proba):.4f}\")\n",
    "\n",
    "    def find_optimal_threshold(self, X, y):\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y, y_pred_proba)\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "        optimal_threshold = thresholds[np.argmax(f1_scores[:-1])]  # Exclude last element as it's always 1\n",
    "        return optimal_threshold\n",
    "\n",
    "    def predict_with_threshold(self, X, threshold):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "\n",
    "    def plot_precision_recall_curve(self, X, y):\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        precisions, recalls, _ = precision_recall_curve(y, y_pred_proba)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(recalls, precisions, marker='.')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.show()\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        feature_importance = self.model.named_steps['classifier'].feature_importances_\n",
    "        preprocessor = self.model.named_steps['preprocessor']\n",
    "        onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_feature_names = onehot_encoder.get_feature_names_out(self.categorical_features).tolist()\n",
    "        feature_names = cat_feature_names + self.numeric_features + self.special_numeric\n",
    "        importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "        return importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    sample_data = pd.DataFrame({\n",
    "        'STRONGEST SNP-RISK ALLELE': np.random.choice(['A-T', 'C-G', 'T-A', 'G-C'], n_samples),\n",
    "        'P-VALUE': np.random.uniform(0, 1, n_samples),\n",
    "        'OR or BETA': np.random.normal(1, 0.5, n_samples),\n",
    "        'RISK ALLELE FREQUENCY': np.random.uniform(0, 1, n_samples),\n",
    "        'PVALUE_MLOG': np.random.uniform(0, 10, n_samples),\n",
    "        'is_alzheimers': np.random.choice([0, 1], n_samples, p=[0.9, 0.1])  # 10% Alzheimer's cases\n",
    "    })\n",
    "\n",
    "    # Split the data\n",
    "    X = sample_data.drop('is_alzheimers', axis=1)\n",
    "    y = sample_data['is_alzheimers']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the improved model\n",
    "    model = ImprovedAlzheimersRiskModel()\n",
    "    model.train(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test, y_test)\n",
    "\n",
    "    # Find optimal threshold\n",
    "    optimal_threshold = model.find_optimal_threshold(X_test, y_test)\n",
    "    print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "    # Evaluate with optimal threshold\n",
    "    y_pred_optimal = model.predict_with_threshold(X_test, optimal_threshold)\n",
    "    print(\"\\nClassification Report with Optimal Threshold:\")\n",
    "    print(classification_report(y_test, y_pred_optimal))\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    model.plot_precision_recall_curve(X_test, y_test)\n",
    "\n",
    "    # Get feature importance\n",
    "    importance_df = model.get_feature_importance()\n",
    "    print(\"\\nTop 5 Important Features:\")\n",
    "    print(importance_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588fb820",
   "metadata": {},
   "source": [
    "# Model using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9f83d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3304b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Users\\14807\\OneDrive\\Spreadsheets\\Data Science Capstone\\AI_ML_Biotech\\Data Collection\\Final Data Merging after Collection\\merged_alzheimers_data.csv')\n",
    "\n",
    "# Create binary target variable\n",
    "df['is_alzheimers'] = df['MAPPED_TRAIT'].str.contains('Alzheimer', case=False, na=False).astype(int)\n",
    "\n",
    "# Select relevant features\n",
    "features = ['STRONGEST SNP-RISK ALLELE', 'P-VALUE', 'OR or BETA', 'RISK ALLELE FREQUENCY', 'PVALUE_MLOG']\n",
    "X = df[features].copy()\n",
    "y = df['is_alzheimers']\n",
    "\n",
    "# Handle 'NR' in 'RISK ALLELE FREQUENCY'\n",
    "X.loc[:, 'RISK ALLELE FREQUENCY'] = X['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "X.loc[:, 'RISK ALLELE FREQUENCY'] = pd.to_numeric(X['RISK ALLELE FREQUENCY'], errors='coerce')\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_features = ['P-VALUE', 'OR or BETA', 'PVALUE_MLOG']\n",
    "categorical_features = ['STRONGEST SNP-RISK ALLELE']\n",
    "special_numeric = ['RISK ALLELE FREQUENCY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2acea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features),\n",
    "        ('special_num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), special_numeric)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14214dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = dict(zip(np.unique(y), len(y) / (len(np.unique(y)) * np.bincount(y))))\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'classifier__scale_pos_weight': [class_weights[1] / class_weights[0]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed12300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 01:36:12,785 - INFO - Best hyperparameters: {'classifier__subsample': 0.8, 'classifier__scale_pos_weight': 27.116129032258062, 'classifier__n_estimators': 300, 'classifier__max_depth': 4, 'classifier__learning_rate': 0.2, 'classifier__colsample_bytree': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "logging.info(f\"Best hyperparameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc99b92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     13429\n",
      "           1       0.80      0.99      0.88       517\n",
      "\n",
      "    accuracy                           0.99     13946\n",
      "   macro avg       0.90      0.99      0.94     13946\n",
      "weighted avg       0.99      0.99      0.99     13946\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13299   130]\n",
      " [    4   513]]\n",
      "\n",
      "ROC-AUC Score: 0.9983513839459134\n",
      "\n",
      "Cross-validation ROC-AUC scores: [0.99991493 0.98523759 0.90520851 0.999997   0.99627071]\n",
      "Mean ROC-AUC: 0.9773 (+/- 0.0729)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba)}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nCross-validation ROC-AUC scores: {cv_scores}\")\n",
    "print(f\"Mean ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735dd4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alzheimers_risk_model.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to predict risk for new data\n",
    "def predict_alzheimers_risk(new_data):\n",
    "    try:\n",
    "        # Handle 'NR' in 'RISK ALLELE FREQUENCY' for new data\n",
    "        new_data = new_data.copy()\n",
    "        new_data.loc[:, 'RISK ALLELE FREQUENCY'] = new_data['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "        new_data.loc[:, 'RISK ALLELE FREQUENCY'] = pd.to_numeric(new_data['RISK ALLELE FREQUENCY'], errors='coerce')\n",
    "        \n",
    "        # Make prediction\n",
    "        risk_probability = best_model.predict_proba(new_data)[0][1]  # Probability of class 1 (Alzheimer's)\n",
    "        return risk_probability * 100  # Convert to percentage\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'alzheimers_risk_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c1d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Alzheimer's risk: 7.92%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "new_person = pd.DataFrame({\n",
    "    'STRONGEST SNP-RISK ALLELE': ['rs429358-C'],\n",
    "    'P-VALUE': [1e-200],\n",
    "    'OR or BETA': [3.685],\n",
    "    'RISK ALLELE FREQUENCY': [0.15],\n",
    "    'PVALUE_MLOG': [200]\n",
    "}, index=[0])\n",
    "\n",
    "risk = predict_alzheimers_risk(new_person)\n",
    "if risk is not None:\n",
    "    print(f\"\\nPredicted Alzheimer's risk: {risk:.2f}%\")\n",
    "else:\n",
    "    print(\"Unable to predict risk due to an error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff12d2",
   "metadata": {},
   "source": [
    "## Full XGBoost code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Users\\14807\\OneDrive\\Spreadsheets\\Data Science Capstone\\AI_ML_Biotech\\Data Collection\\Final Data Merging after Collection\\merged_alzheimers_data.csv')\n",
    "\n",
    "# Create binary target variable\n",
    "df['is_alzheimers'] = df['MAPPED_TRAIT'].str.contains('Alzheimer', case=False, na=False).astype(int)\n",
    "\n",
    "# Select relevant features\n",
    "features = ['STRONGEST SNP-RISK ALLELE', 'P-VALUE', 'OR or BETA', 'RISK ALLELE FREQUENCY', 'PVALUE_MLOG']\n",
    "X = df[features].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "y = df['is_alzheimers']\n",
    "\n",
    "# Handle 'NR' in 'RISK ALLELE FREQUENCY'\n",
    "X.loc[:, 'RISK ALLELE FREQUENCY'] = X['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "X.loc[:, 'RISK ALLELE FREQUENCY'] = pd.to_numeric(X['RISK ALLELE FREQUENCY'], errors='coerce')\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_features = ['P-VALUE', 'OR or BETA', 'PVALUE_MLOG']\n",
    "categorical_features = ['STRONGEST SNP-RISK ALLELE']\n",
    "special_numeric = ['RISK ALLELE FREQUENCY']\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features),\n",
    "        ('special_num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value=-1)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), special_numeric)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "# The rest of the code remains the same...\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = dict(zip(np.unique(y), len(y) / (len(np.unique(y)) * np.bincount(y))))\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'classifier__scale_pos_weight': [class_weights[1] / class_weights[0]]\n",
    "}\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "logging.info(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba)}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='roc_auc')\n",
    "print(f\"\\nCross-validation ROC-AUC scores: {cv_scores}\")\n",
    "print(f\"Mean ROC-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Function to predict risk for new data\n",
    "def predict_alzheimers_risk(new_data):\n",
    "    try:\n",
    "        # Handle 'NR' in 'RISK ALLELE FREQUENCY' for new data\n",
    "        new_data = new_data.copy()\n",
    "        new_data.loc[:, 'RISK ALLELE FREQUENCY'] = new_data['RISK ALLELE FREQUENCY'].replace('NR', np.nan)\n",
    "        new_data.loc[:, 'RISK ALLELE FREQUENCY'] = pd.to_numeric(new_data['RISK ALLELE FREQUENCY'], errors='coerce')\n",
    "        \n",
    "        # Make prediction\n",
    "        risk_probability = best_model.predict_proba(new_data)[0][1]  # Probability of class 1 (Alzheimer's)\n",
    "        return risk_probability * 100  # Convert to percentage\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'alzheimers_risk_model.joblib')\n",
    "\n",
    "# Example usage\n",
    "new_person = pd.DataFrame({\n",
    "    'STRONGEST SNP-RISK ALLELE': ['rs429358-C'],\n",
    "    'P-VALUE': [1e-200],\n",
    "    'OR or BETA': [3.685],\n",
    "    'RISK ALLELE FREQUENCY': [0.15],\n",
    "    'PVALUE_MLOG': [200]\n",
    "}, index=[0])\n",
    "\n",
    "risk = predict_alzheimers_risk(new_person)\n",
    "if risk is not None:\n",
    "    print(f\"\\nPredicted Alzheimer's risk: {risk:.2f}%\")\n",
    "else:\n",
    "    print(\"Unable to predict risk due to an error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b3e29",
   "metadata": {},
   "source": [
    "## Path of XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11ef22e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file exists!\n",
      "File size: 439945 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists('alzheimers_risk_model.joblib'):\n",
    "    print(\"Model file exists!\")\n",
    "    print(\"File size:\", os.path.getsize('alzheimers_risk_model.joblib'), \"bytes\")\n",
    "else:\n",
    "    print(\"Model file not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "becea99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path of the model: C:\\Users\\14807\\alzheimers_risk_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.abspath('alzheimers_risk_model.joblib')\n",
    "print(\"Full path of the model:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "480d10f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('alzheimers_risk_model.joblib')\n",
    "\n",
    "# Test prediction with the loaded model\n",
    "test_prediction = loaded_model.predict(X_test[:1])\n",
    "print(\"Test prediction:\", test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcc161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd3cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5655c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81da759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2f2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878d5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
